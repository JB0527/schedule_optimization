{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 확인\n",
        "\n",
        "\n",
        "1.   Raw 데이터\n",
        "2.   GT값 (휴리스틱라벨링)\n",
        "3.   정규분포에 따른 데이터 필터링\n",
        "4.   our 데이터 전처리 시스템\n"
      ],
      "metadata": {
        "id": "MrY8jghZJEtU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "#1\n",
        "#file_path = 'pipe_final.xlsx'\n",
        "#2\n",
        "#file_path = 'heuristic_data.xlsx'\n",
        "#3\n",
        "#file_path = 'filter_pipe_final_241007.xlsx'\n",
        "#4\n",
        "#file_path = 'updated_total.xlsx'\n",
        "#5\n",
        "file_path = 'updated_total_filter.xlsx'\n",
        "\n",
        "data = pd.read_excel(file_path).dropna()\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "id": "OqStIyWyXZ9v",
        "outputId": "325e413f-07c8-4ef5-ab87-7d4250d91b66"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           제품군   외경/폭     두께  등록 길이  등록 중량  step1 최종 작업 시간  step2 최종 작업 시간  \\\n",
              "0    23A012-01  610.0  23.83    6.0  2.067             9.7            10.2   \n",
              "1    23A012-02  914.0  12.70   11.8  3.332             8.9             9.6   \n",
              "2    23A012-03  914.0  12.70   11.5  3.247             8.5             9.5   \n",
              "3    23A012-04  914.0  12.70    6.1  1.722             8.9             9.2   \n",
              "4    23A029-19  914.0  34.00   11.0  8.117            10.7            11.5   \n",
              "..         ...    ...    ...    ...    ...             ...             ...   \n",
              "121  23Y020-04  864.0   9.50    6.0  1.202             5.4             9.9   \n",
              "122  23Y022-01  762.0   9.50    6.0  1.058             6.5            10.2   \n",
              "123  23Y023-01  762.0  25.40   11.8  5.445            11.6            11.7   \n",
              "124  23Y023-02  914.0  30.18   11.8  7.762            13.2            12.8   \n",
              "125  23Y023-03  914.0  30.18   11.8  7.762             7.3            12.4   \n",
              "\n",
              "     step3 최종 작업 시간  step4 최종 작업 시간  step5 최종 작업 시간  step6 최종 작업 시간  filter  \n",
              "0              10.6             4.2            14.0            22.3       0  \n",
              "1               8.9             8.9            11.0            13.9       0  \n",
              "2               7.7             7.2             3.5            12.5       0  \n",
              "3              10.6            10.5            11.4            20.5       0  \n",
              "4              10.4            10.3            16.5            21.8       0  \n",
              "..              ...             ...             ...             ...     ...  \n",
              "121            10.5             9.4            14.0            21.6       0  \n",
              "122             8.1            11.4            20.7            17.9       0  \n",
              "123             7.3             9.4            18.5            10.4       0  \n",
              "124             8.4             8.1             8.0            18.0       0  \n",
              "125            10.7             6.6             6.8            16.1       0  \n",
              "\n",
              "[86 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8808a689-2de0-475e-ab1b-7ce3fa10687f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>제품군</th>\n",
              "      <th>외경/폭</th>\n",
              "      <th>두께</th>\n",
              "      <th>등록 길이</th>\n",
              "      <th>등록 중량</th>\n",
              "      <th>step1 최종 작업 시간</th>\n",
              "      <th>step2 최종 작업 시간</th>\n",
              "      <th>step3 최종 작업 시간</th>\n",
              "      <th>step4 최종 작업 시간</th>\n",
              "      <th>step5 최종 작업 시간</th>\n",
              "      <th>step6 최종 작업 시간</th>\n",
              "      <th>filter</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>23A012-01</td>\n",
              "      <td>610.0</td>\n",
              "      <td>23.83</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.067</td>\n",
              "      <td>9.7</td>\n",
              "      <td>10.2</td>\n",
              "      <td>10.6</td>\n",
              "      <td>4.2</td>\n",
              "      <td>14.0</td>\n",
              "      <td>22.3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>23A012-02</td>\n",
              "      <td>914.0</td>\n",
              "      <td>12.70</td>\n",
              "      <td>11.8</td>\n",
              "      <td>3.332</td>\n",
              "      <td>8.9</td>\n",
              "      <td>9.6</td>\n",
              "      <td>8.9</td>\n",
              "      <td>8.9</td>\n",
              "      <td>11.0</td>\n",
              "      <td>13.9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>23A012-03</td>\n",
              "      <td>914.0</td>\n",
              "      <td>12.70</td>\n",
              "      <td>11.5</td>\n",
              "      <td>3.247</td>\n",
              "      <td>8.5</td>\n",
              "      <td>9.5</td>\n",
              "      <td>7.7</td>\n",
              "      <td>7.2</td>\n",
              "      <td>3.5</td>\n",
              "      <td>12.5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>23A012-04</td>\n",
              "      <td>914.0</td>\n",
              "      <td>12.70</td>\n",
              "      <td>6.1</td>\n",
              "      <td>1.722</td>\n",
              "      <td>8.9</td>\n",
              "      <td>9.2</td>\n",
              "      <td>10.6</td>\n",
              "      <td>10.5</td>\n",
              "      <td>11.4</td>\n",
              "      <td>20.5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>23A029-19</td>\n",
              "      <td>914.0</td>\n",
              "      <td>34.00</td>\n",
              "      <td>11.0</td>\n",
              "      <td>8.117</td>\n",
              "      <td>10.7</td>\n",
              "      <td>11.5</td>\n",
              "      <td>10.4</td>\n",
              "      <td>10.3</td>\n",
              "      <td>16.5</td>\n",
              "      <td>21.8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>23Y020-04</td>\n",
              "      <td>864.0</td>\n",
              "      <td>9.50</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.202</td>\n",
              "      <td>5.4</td>\n",
              "      <td>9.9</td>\n",
              "      <td>10.5</td>\n",
              "      <td>9.4</td>\n",
              "      <td>14.0</td>\n",
              "      <td>21.6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>23Y022-01</td>\n",
              "      <td>762.0</td>\n",
              "      <td>9.50</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.058</td>\n",
              "      <td>6.5</td>\n",
              "      <td>10.2</td>\n",
              "      <td>8.1</td>\n",
              "      <td>11.4</td>\n",
              "      <td>20.7</td>\n",
              "      <td>17.9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>23Y023-01</td>\n",
              "      <td>762.0</td>\n",
              "      <td>25.40</td>\n",
              "      <td>11.8</td>\n",
              "      <td>5.445</td>\n",
              "      <td>11.6</td>\n",
              "      <td>11.7</td>\n",
              "      <td>7.3</td>\n",
              "      <td>9.4</td>\n",
              "      <td>18.5</td>\n",
              "      <td>10.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>23Y023-02</td>\n",
              "      <td>914.0</td>\n",
              "      <td>30.18</td>\n",
              "      <td>11.8</td>\n",
              "      <td>7.762</td>\n",
              "      <td>13.2</td>\n",
              "      <td>12.8</td>\n",
              "      <td>8.4</td>\n",
              "      <td>8.1</td>\n",
              "      <td>8.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>23Y023-03</td>\n",
              "      <td>914.0</td>\n",
              "      <td>30.18</td>\n",
              "      <td>11.8</td>\n",
              "      <td>7.762</td>\n",
              "      <td>7.3</td>\n",
              "      <td>12.4</td>\n",
              "      <td>10.7</td>\n",
              "      <td>6.6</td>\n",
              "      <td>6.8</td>\n",
              "      <td>16.1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>86 rows × 12 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8808a689-2de0-475e-ab1b-7ce3fa10687f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8808a689-2de0-475e-ab1b-7ce3fa10687f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8808a689-2de0-475e-ab1b-7ce3fa10687f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7051eb53-b0c3-40a7-b84b-71cdabd7020b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7051eb53-b0c3-40a7-b84b-71cdabd7020b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7051eb53-b0c3-40a7-b84b-71cdabd7020b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_4e0fa42e-455f-4097-8b66-f1f470c0eb4d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4e0fa42e-455f-4097-8b66-f1f470c0eb4d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 86,\n  \"fields\": [\n    {\n      \"column\": \"\\uc81c\\ud488\\uad70\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 86,\n        \"samples\": [\n          \"23Y016-02\",\n          \"23A012-01\",\n          \"23E019-01\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc678\\uacbd/\\ud3ed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 208.66835251333464,\n        \"min\": 450.0,\n        \"max\": 1219.0,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          457.2,\n          609.6,\n          610.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ub450\\uaed8\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.64599090469796,\n        \"min\": 7.9,\n        \"max\": 45.0,\n        \"num_unique_values\": 29,\n        \"samples\": [\n          45.0,\n          32.54,\n          11.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ub4f1\\ub85d \\uae38\\uc774\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.6046442163913386,\n        \"min\": 6.0,\n        \"max\": 12.192,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          6.0,\n          9.43,\n          9.56\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ub4f1\\ub85d \\uc911\\ub7c9\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.648408558941622,\n        \"min\": 0.775,\n        \"max\": 12.732,\n        \"num_unique_values\": 68,\n        \"samples\": [\n          1.886,\n          2.123,\n          8.117\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"step1 \\ucd5c\\uc885 \\uc791\\uc5c5 \\uc2dc\\uac04\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.3968207396471555,\n        \"min\": 5.4,\n        \"max\": 21.1,\n        \"num_unique_values\": 54,\n        \"samples\": [\n          9.5,\n          5.4,\n          15.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"step2 \\ucd5c\\uc885 \\uc791\\uc5c5 \\uc2dc\\uac04\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.8069288287217249,\n        \"min\": 6.0,\n        \"max\": 18.0,\n        \"num_unique_values\": 48,\n        \"samples\": [\n          13.1,\n          10.3,\n          12.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"step3 \\ucd5c\\uc885 \\uc791\\uc5c5 \\uc2dc\\uac04\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.3226005520134985,\n        \"min\": 1.8,\n        \"max\": 15.7,\n        \"num_unique_values\": 58,\n        \"samples\": [\n          10.6,\n          8.8,\n          9.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"step4 \\ucd5c\\uc885 \\uc791\\uc5c5 \\uc2dc\\uac04\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.5332246418711684,\n        \"min\": 0.9,\n        \"max\": 13.8,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          7.7,\n          12.3,\n          13.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"step5 \\ucd5c\\uc885 \\uc791\\uc5c5 \\uc2dc\\uac04\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.848732470073749,\n        \"min\": 0.1,\n        \"max\": 22.8,\n        \"num_unique_values\": 58,\n        \"samples\": [\n          14.0,\n          13.2,\n          10.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"step6 \\ucd5c\\uc885 \\uc791\\uc5c5 \\uc2dc\\uac04\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 47.36928962079975,\n        \"min\": 6.1,\n        \"max\": 454.8,\n        \"num_unique_values\": 61,\n        \"samples\": [\n          22.3,\n          19.1,\n          11.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"filter\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## input(외경/폭,등록길이,두께)에 따른 소요시간 값 예측 모델링"
      ],
      "metadata": {
        "id": "Q6_RSFMhGiJm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 예측 및 평가 MAE(mean absolute error)로 값 계산하고 feature에 대한 중요도를 판별해서 input 값으로 사용"
      ],
      "metadata": {
        "id": "IY5O7AkSKcbb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- RandomForestRegressor 모델 이용"
      ],
      "metadata": {
        "id": "SzE0ohgkJIXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.inspection import permutation_importance\n",
        "import pandas as pd\n",
        "\n",
        "# 1. 데이터 불러오고 빈 데이터 없애기\n",
        "data = pd.read_excel(file_path).dropna()\n",
        "\n",
        "#2. 입력 변수(X)와 출력 변수(y) 설정\n",
        "X = data[['외경/폭', '두께', '등록 길이']]#,'등록 중량']]\n",
        "y = data[['step1 최종 작업 시간', 'step2 최종 작업 시간',\n",
        "         'step3 최종 작업 시간', 'step4 최종 작업 시간',\n",
        "         'step5 최종 작업 시간', 'step6 최종 작업 시간']]\n",
        "\n",
        "# 3. 훈련/테스트 데이터 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 4. 다중 출력 회귀 모델 학습 (랜덤 포레스트)\n",
        "model = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=42))\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 5. 예측 및 평가\n",
        "y_pred = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred, multioutput='raw_values')\n",
        "print(f'Step-wise Mean Absolute Error: {mae}')\n",
        "\n",
        "# 6. 예측 결과 확인\n",
        "print(f'Predicted Times for each step: {y_pred[:5]}')\n",
        "# 6. Permutation Importance 계산\n",
        "perm_importance = permutation_importance(model, X_test, y_test, n_repeats=10, random_state=42)\n",
        "\n",
        "# 7. 피처 중요도 출력\n",
        "feature_importances = pd.DataFrame(perm_importance.importances_mean, index=X.columns, columns=['Importance'])\n",
        "print(\"각 입력 변수의 중요도:\")\n",
        "print(feature_importances)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHP9mJRBDNsg",
        "outputId": "69ffecd3-c210-4aa8-abe7-d0ffdef38f52"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step-wise Mean Absolute Error: [1.70011296 1.05172714 1.52127844 1.94818929 4.53957262 3.72119405]\n",
            "Predicted Times for each step: [[ 7.101      12.15457143  8.9058      9.74375    16.289      16.627     ]\n",
            " [13.11086667 11.44386667  9.63173333 11.07725     8.9935     16.533     ]\n",
            " [ 7.65010476 10.87667143  9.01468333  8.99386667 12.29675    14.81471667]\n",
            " [10.95067619 11.0853381  11.4566619  11.78969048  0.8423381  14.39584286]\n",
            " [13.8372     12.16308333  6.8954      7.7813     12.6595     17.6346    ]]\n",
            "각 입력 변수의 중요도:\n",
            "       Importance\n",
            "외경/폭     0.140386\n",
            "두께       0.282847\n",
            "등록 길이    0.008192\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터에 따른 맞춤 변수 고려\n",
        "\"\"\"\n",
        "4,5 데이터 기준\n",
        "file_path = 'updated_total.xlsx'\n",
        "data = pd.read_excel(file_path)\n",
        "\n",
        "#2. 입력 변수(X)와 출력 변수(y) 설정\n",
        "X = data[['외경/폭', '두께', '등록 길이']]#,'등록 중량']]\n",
        "y = data[['step1 최종 작업 시간', 'step2 최종 작업 시간',\n",
        "         'step3 최종 작업 시간', 'step4 최종 작업 시간',\n",
        "         'step5 최종 작업 시간', 'step6 최종 작업 시간']]\n",
        "--------------------------------------------------------------------------\n",
        "1,2,3 데이터기준\n",
        "# 2. 입력 변수(X)와 출력 변수(y) 설정\n",
        "X = data[['외경/폭(mm)', '두께(mm)', '등록 길이(m)','등록 중량(ton)']]\n",
        "#X = data[['외경/폭', '등록 길이','두께']]\n",
        "y = data[['step1 작업 시간(분)', 'step2 작업 시간(분)',\n",
        "         'step3 작업 시간(분)', 'step4 작업 시간(분)',\n",
        "         'step5 작업 시간(분)', 'step6 작업 시간(분)']]\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "erzF2ObWfKpc",
        "outputId": "1e713f1b-0607-474e-e166-4be3a54a41f1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n4,5 데이터 기준\\nfile_path = 'updated_total.xlsx'\\ndata = pd.read_excel(file_path)\\n\\n#2. 입력 변수(X)와 출력 변수(y) 설정\\nX = data[['외경/폭', '두께', '등록 길이']]#,'등록 중량']]\\ny = data[['step1 최종 작업 시간', 'step2 최종 작업 시간',\\n         'step3 최종 작업 시간', 'step4 최종 작업 시간',\\n         'step5 최종 작업 시간', 'step6 최종 작업 시간']]\\n--------------------------------------------------------------------------\\n1,2,3 데이터기준\\n# 2. 입력 변수(X)와 출력 변수(y) 설정\\nX = data[['외경/폭(mm)', '두께(mm)', '등록 길이(m)','등록 중량(ton)']]\\n#X = data[['외경/폭', '등록 길이','두께']]\\ny = data[['step1 작업 시간(분)', 'step2 작업 시간(분)',\\n         'step3 작업 시간(분)', 'step4 작업 시간(분)',\\n         'step5 작업 시간(분)', 'step6 작업 시간(분)']]\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP regression 모델 사용"
      ],
      "metadata": {
        "id": "i9n9A1bhe1jj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#사용x\n",
        "import pandas as pd\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# 1. 데이터 불러오고 빈 데이터 없애기\n",
        "data = pd.read_excel(file_path).dropna()\n",
        "\n",
        "\n",
        "#2. 입력 변수(X)와 출력 변수(y) 설정\n",
        "X = data[['외경/폭', '두께', '등록 길이']]#,'등록 중량']]\n",
        "y = data[['step1 최종 작업 시간', 'step2 최종 작업 시간',\n",
        "         'step3 최종 작업 시간', 'step4 최종 작업 시간',\n",
        "         'step5 최종 작업 시간', 'step6 최종 작업 시간']]\n",
        "# 3. 훈련/테스트 데이터 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 4. MLP 회귀 모델 학습\n",
        "mlp = MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42)\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# 5. 모델 성능 평가\n",
        "y_pred = mlp.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred, multioutput='raw_values')\n",
        "print(f\"Step-wise Mean Absolute Error: {mae}\")\n",
        "\n",
        "# 6. Permutation Importance 계산\n",
        "perm_importance = permutation_importance(mlp, X_test, y_test, n_repeats=10, random_state=42)\n",
        "\n",
        "# 7. 피처 중요도 출력\n",
        "feature_importances = pd.DataFrame(perm_importance.importances_mean, index=X.columns, columns=['Importance'])\n",
        "print(\"각 입력 변수의 중요도:\")\n",
        "print(feature_importances)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdBYuPTaJKU_",
        "outputId": "4fbe5973-bd95-4e28-b7b8-3c0d51bde05e",
        "collapsed": true
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step-wise Mean Absolute Error: [15.27695945  5.70038037  4.28242795  2.61483122 15.75941816  4.30224834]\n",
            "각 입력 변수의 중요도:\n",
            "       Importance\n",
            "외경/폭     0.065050\n",
            "두께      -0.246131\n",
            "등록 길이    0.070647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 필터링 데이터에 대한 MLP regressor"
      ],
      "metadata": {
        "id": "aZC24QJqfUvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# 1. 데이터 불러오기\n",
        "data = pd.read_excel(file_path).dropna()\n",
        "  # null값이 있는 행을 제거\n",
        "\n",
        "#2. 입력 변수(X)와 출력 변수(y) 설정\n",
        "X = data[['외경/폭', '두께', '등록 길이']]#,'등록 중량']]\n",
        "y = data[['step1 최종 작업 시간', 'step2 최종 작업 시간',\n",
        "         'step3 최종 작업 시간', 'step4 최종 작업 시간',\n",
        "         'step5 최종 작업 시간', 'step6 최종 작업 시간']]\n",
        "# 3. 훈련/테스트 데이터 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 4. MLP 회귀 모델 학습\n",
        "mlp = MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42)\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# 5. 모델 성능 평가\n",
        "y_pred = mlp.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred, multioutput='raw_values')\n",
        "print(f\"Step-wise Mean Absolute Error: {mae}\")\n",
        "\n",
        "# 6. Permutation Importance 계산\n",
        "perm_importance = permutation_importance(mlp, X_test, y_test, n_repeats=10, random_state=42)\n",
        "\n",
        "# 7. 피처 중요도 출력\n",
        "feature_importances = pd.DataFrame(perm_importance.importances_mean, index=X.columns, columns=['Importance'])\n",
        "print(\"각 입력 변수의 중요도:\")\n",
        "print(feature_importances)\n"
      ],
      "metadata": {
        "id": "kgUDoY0tMSjL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dfaa4e6-11bf-4ec5-8034-4964c7fa6101"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step-wise Mean Absolute Error: [15.27695945  5.70038037  4.28242795  2.61483122 15.75941816  4.30224834]\n",
            "각 입력 변수의 중요도:\n",
            "       Importance\n",
            "외경/폭     0.065050\n",
            "두께      -0.246131\n",
            "등록 길이    0.070647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# 1. 데이터 불러오기\n",
        "data = pd.read_excel(file_path).dropna()\n",
        "  # null값이 있는 행을 제거\n",
        "\n",
        "#2. 입력 변수(X)와 출력 변수(y) 설정\n",
        "X = data[['외경/폭', '두께', '등록 길이']]#,'등록 중량']]\n",
        "y = data[['step1 최종 작업 시간', 'step2 최종 작업 시간',\n",
        "         'step3 최종 작업 시간', 'step4 최종 작업 시간',\n",
        "         'step5 최종 작업 시간', 'step6 최종 작업 시간']]\n",
        "# 3. 훈련/테스트 데이터 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 4. MLP 회귀 모델 학습\n",
        "mlp = MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42)\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# 5. 모델 성능 평가\n",
        "y_pred = mlp.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred, multioutput='raw_values')\n",
        "print(f\"Step-wise Mean Absolute Error: {mae}\")\n",
        "\n",
        "# 6. Permutation Importance 계산\n",
        "perm_importance = permutation_importance(mlp, X_test, y_test, n_repeats=10, random_state=42)\n",
        "\n",
        "# 7. 피처 중요도 출력\n",
        "feature_importances = pd.DataFrame(perm_importance.importances_mean, index=X.columns, columns=['Importance'])\n",
        "print(\"각 입력 변수의 중요도:\")\n",
        "print(feature_importances)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6P06nD02bzEb",
        "outputId": "c66e53ea-8e22-42cc-8aa3-4cde1d63946b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step-wise Mean Absolute Error: [15.27695945  5.70038037  4.28242795  2.61483122 15.75941816  4.30224834]\n",
            "각 입력 변수의 중요도:\n",
            "       Importance\n",
            "외경/폭     0.065050\n",
            "두께      -0.246131\n",
            "등록 길이    0.070647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP layer를 쌓아 학습에 사용"
      ],
      "metadata": {
        "id": "odiSldccqvYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# 1. 데이터 불러오기 및 전처리\n",
        "data = pd.read_excel(file_path).dropna()\n",
        "  # null값이 있는 행을 제거\n",
        "\n",
        "\n",
        "#2. 입력 변수(X)와 출력 변수(y) 설정\n",
        "X = data[['외경/폭', '두께', '등록 길이']]#,'등록 중량']]\n",
        "y = data[['step1 최종 작업 시간', 'step2 최종 작업 시간',\n",
        "         'step3 최종 작업 시간', 'step4 최종 작업 시간',\n",
        "         'step5 최종 작업 시간', 'step6 최종 작업 시간']]\n",
        "\n",
        "# 데이터 분할\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 특성 스케일링\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# 2. 신경망 모델 구축\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(6)  # 출력 노드 수는 예측하고자 하는 작업 시간의 수\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# 3. 모델 학습\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32,\n",
        "                    validation_split=0, verbose=1)\n",
        "\n",
        "# 4. 모델 평가\n",
        "loss, mae = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('\\n신경망 모델 평가:')\n",
        "print('테스트 세트의 MSE:', loss)\n",
        "print('테스트 세트의 MAE:', mae)\n",
        "\n",
        "# 각 스텝별 평가 지표 계산\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "for i, step in enumerate(['step1', 'step2', 'step3', 'step4', 'step5', 'step6']):\n",
        "    print(f\"\\n{step} 작업 시간(분) 평가:\")\n",
        "    mse = mean_squared_error(y_test.iloc[:, i], y_pred[:, i])\n",
        "    mae = mean_absolute_error(y_test.iloc[:, i], y_pred[:, i])\n",
        "    r2 = r2_score(y_test.iloc[:, i], y_pred[:, i])\n",
        "    print('MSE:', mse)\n",
        "    print('MAE:', mae)\n",
        "    print('R² 점수:', r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNQrQSA5qw3w",
        "outputId": "cfb2c8df-747a-4b95-a77e-4cec3468b661"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 528.9370 - mae: 12.0060\n",
            "Epoch 2/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 527.1936 - mae: 11.9578 \n",
            "Epoch 3/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 794.4841 - mae: 12.4748  \n",
            "Epoch 4/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 791.6998 - mae: 12.4066  \n",
            "Epoch 5/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 523.2440 - mae: 11.8218 \n",
            "Epoch 6/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 524.5997 - mae: 11.8779 \n",
            "Epoch 7/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 519.9056 - mae: 11.6944 \n",
            "Epoch 8/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 787.5362 - mae: 12.2448  \n",
            "Epoch 9/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 384.8391 - mae: 11.3737 \n",
            "Epoch 10/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 782.8729 - mae: 12.1227  \n",
            "Epoch 11/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 511.9474 - mae: 11.3827 \n",
            "Epoch 12/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 780.7538 - mae: 12.0529  \n",
            "Epoch 13/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 776.8932 - mae: 11.9119  \n",
            "Epoch 14/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 509.1435 - mae: 11.2817 \n",
            "Epoch 15/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 506.5414 - mae: 11.1951 \n",
            "Epoch 16/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 500.6843 - mae: 10.9707\n",
            "Epoch 17/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 764.3025 - mae: 11.4089  \n",
            "Epoch 18/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 764.0425 - mae: 11.4122  \n",
            "Epoch 19/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 758.9301 - mae: 11.2005  \n",
            "Epoch 20/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 755.5156 - mae: 11.0809  \n",
            "Epoch 21/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 750.5109 - mae: 10.8607  \n",
            "Epoch 22/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 347.6529 - mae: 9.7693\n",
            "Epoch 23/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 740.5997 - mae: 10.4247  \n",
            "Epoch 24/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 738.0090 - mae: 10.3525  \n",
            "Epoch 25/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 467.2051 - mae: 9.4459\n",
            "Epoch 26/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 461.9097 - mae: 9.1742 \n",
            "Epoch 27/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 720.0059 - mae: 9.4827   \n",
            "Epoch 28/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 452.4061 - mae: 8.6593\n",
            "Epoch 29/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 446.9381 - mae: 8.3781\n",
            "Epoch 30/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 440.4590 - mae: 7.9517\n",
            "Epoch 31/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 696.7914 - mae: 8.2298  \n",
            "Epoch 32/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 432.8033 - mae: 7.5033\n",
            "Epoch 33/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 426.5336 - mae: 7.1094\n",
            "Epoch 34/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 421.5216 - mae: 6.7226\n",
            "Epoch 35/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 415.3770 - mae: 6.3273\n",
            "Epoch 36/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 667.5071 - mae: 6.3943  \n",
            "Epoch 37/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 662.5182 - mae: 6.0944  \n",
            "Epoch 38/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 658.6440 - mae: 5.8606  \n",
            "Epoch 39/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 653.5359 - mae: 5.5214  \n",
            "Epoch 40/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 265.0351 - mae: 4.4068\n",
            "Epoch 41/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 389.8045 - mae: 4.4851\n",
            "Epoch 42/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 385.5479 - mae: 4.1704\n",
            "Epoch 43/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 382.8015 - mae: 4.0136\n",
            "Epoch 44/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 632.0421 - mae: 4.3849  \n",
            "Epoch 45/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 378.5986 - mae: 3.8576\n",
            "Epoch 46/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 375.8638 - mae: 3.7275\n",
            "Epoch 47/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 249.7956 - mae: 3.4302\n",
            "Epoch 48/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 372.7863 - mae: 3.6813\n",
            "Epoch 49/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 370.1314 - mae: 3.5647\n",
            "Epoch 50/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 367.7313 - mae: 3.4242\n",
            "Epoch 51/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 612.2933 - mae: 3.9989 \n",
            "Epoch 52/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 610.0750 - mae: 3.9824 \n",
            "Epoch 53/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 364.1823 - mae: 3.4408\n",
            "Epoch 54/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 363.0611 - mae: 3.4317\n",
            "Epoch 55/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 605.7710 - mae: 4.0254 \n",
            "Epoch 56/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 604.0635 - mae: 4.0100 \n",
            "Epoch 57/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 602.0004 - mae: 3.9189 \n",
            "Epoch 58/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 600.8627 - mae: 3.9609 \n",
            "Epoch 59/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 599.9774 - mae: 3.9894 \n",
            "Epoch 60/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 357.7244 - mae: 3.4022\n",
            "Epoch 61/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 356.9259 - mae: 3.3834\n",
            "Epoch 62/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 595.4387 - mae: 3.9643 \n",
            "Epoch 63/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 355.9258 - mae: 3.4188\n",
            "Epoch 64/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 355.1375 - mae: 3.4138\n",
            "Epoch 65/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 591.8473 - mae: 3.9557 \n",
            "Epoch 66/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 590.3091 - mae: 3.9420 \n",
            "Epoch 67/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 352.6811 - mae: 3.3762\n",
            "Epoch 68/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 588.4271 - mae: 4.0191 \n",
            "Epoch 69/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 350.3659 - mae: 3.3288\n",
            "Epoch 70/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 585.3224 - mae: 3.9399 \n",
            "Epoch 71/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 349.9834 - mae: 3.4170\n",
            "Epoch 72/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 349.3805 - mae: 3.4258\n",
            "Epoch 73/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 348.7357 - mae: 3.3953\n",
            "Epoch 74/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 581.2488 - mae: 3.9924 \n",
            "Epoch 75/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 579.9669 - mae: 4.0147 \n",
            "Epoch 76/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 346.9333 - mae: 3.4630\n",
            "Epoch 77/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 577.4229 - mae: 4.0537 \n",
            "Epoch 78/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 345.3227 - mae: 3.4495\n",
            "Epoch 79/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 575.2292 - mae: 4.0607 \n",
            "Epoch 80/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 573.1583 - mae: 4.0037 \n",
            "Epoch 81/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 343.2032 - mae: 3.4767\n",
            "Epoch 82/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 343.2354 - mae: 3.5252\n",
            "Epoch 83/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 569.7208 - mae: 3.9967 \n",
            "Epoch 84/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 568.6058 - mae: 4.0271 \n",
            "Epoch 85/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 341.9174 - mae: 3.5570\n",
            "Epoch 86/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 227.6212 - mae: 3.2244\n",
            "Epoch 87/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 226.6320 - mae: 3.2720\n",
            "Epoch 88/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 561.0444 - mae: 4.1019 \n",
            "Epoch 89/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 556.9650 - mae: 4.1975 \n",
            "Epoch 90/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 335.0013 - mae: 3.7860\n",
            "Epoch 91/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 551.5663 - mae: 4.3916 \n",
            "Epoch 92/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 549.5665 - mae: 4.4254 \n",
            "Epoch 93/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 331.2852 - mae: 3.8053\n",
            "Epoch 94/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 547.9285 - mae: 4.5384 \n",
            "Epoch 95/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 543.0298 - mae: 4.3572 \n",
            "Epoch 96/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 329.0484 - mae: 3.8203\n",
            "Epoch 97/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 330.0449 - mae: 3.8697\n",
            "Epoch 98/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 329.1749 - mae: 3.8441\n",
            "Epoch 99/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 330.1575 - mae: 3.9273\n",
            "Epoch 100/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 328.1963 - mae: 3.7724\n",
            "\n",
            "신경망 모델 평가:\n",
            "테스트 세트의 MSE: 16.729148864746094\n",
            "테스트 세트의 MAE: 2.7124454975128174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7b6a81f29630> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\n",
            "step1 작업 시간(분) 평가:\n",
            "MSE: 5.578814056926266\n",
            "MAE: 1.5875578668382433\n",
            "R² 점수: -0.4254901415951846\n",
            "\n",
            "step2 작업 시간(분) 평가:\n",
            "MSE: 4.409934512101896\n",
            "MAE: 1.5476973639594185\n",
            "R² 점수: -1.0662898695874334\n",
            "\n",
            "step3 작업 시간(분) 평가:\n",
            "MSE: 4.443637891047612\n",
            "MAE: 1.7725357320573596\n",
            "R² 점수: -0.24307222066760503\n",
            "\n",
            "step4 작업 시간(분) 평가:\n",
            "MSE: 6.178061379096203\n",
            "MAE: 1.938811355166965\n",
            "R² 점수: -0.3282979553718546\n",
            "\n",
            "step5 작업 시간(분) 평가:\n",
            "MSE: 31.250714447353644\n",
            "MAE: 4.433286343680488\n",
            "R² 점수: -0.0013401809533708509\n",
            "\n",
            "step6 작업 시간(분) 평가:\n",
            "MSE: 48.51374439219285\n",
            "MAE: 4.994784492916532\n",
            "R² 점수: -2.393301926313735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 신경망 모델을 사용했을 경우 저장\n",
        "model.save('my_model.h5')\n",
        "\n",
        "# 신경망 모델 로드\n",
        "from tensorflow.keras.models import load_model\n",
        "loaded_model = load_model('my_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "4Xjdvj7wqxQe",
        "outputId": "2b55ecdf-d6b0-485f-8c4f-1abb75fe4da0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Could not locate function 'mse'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'keras.metrics', 'class_name': 'function', 'config': 'mse', 'registered_name': 'mse'}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-28029185e860>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 신경망 모델 로드\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mloaded_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'my_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    187\u001b[0m         )\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         return legacy_h5_format.load_model_from_hdf5(\n\u001b[0m\u001b[1;32m    190\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/legacy/saving/legacy_h5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;31m# Compile model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             model.compile(\n\u001b[0;32m--> 155\u001b[0;31m                 **saving_utils.compile_args_from_training_config(\n\u001b[0m\u001b[1;32m    156\u001b[0m                     \u001b[0mtraining_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/legacy/saving/saving_utils.py\u001b[0m in \u001b[0;36mcompile_args_from_training_config\u001b[0;34m(training_config, custom_objects)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mloss_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mloss_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deserialize_nested_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeserialize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m             \u001b[0;31m# Ensure backwards compatibility for losses in legacy H5 files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_resolve_compile_arguments_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/legacy/saving/saving_utils.py\u001b[0m in \u001b[0;36m_deserialize_nested_config\u001b[0;34m(deserialize_fn, config)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_single_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         return {\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/losses/__init__.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(name, custom_objects)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mKeras\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mLoss\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0ma\u001b[0m \u001b[0mloss\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \"\"\"\n\u001b[0;32m--> 149\u001b[0;31m     return serialization_lib.deserialize_keras_object(\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mALL_OBJECTS_DICT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/serialization_lib.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFunctionType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m                 return deserialize_keras_object(\n\u001b[0m\u001b[1;32m    576\u001b[0m                     serialize_with_public_fn(\n\u001b[1;32m    577\u001b[0m                         \u001b[0mmodule_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_module_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/serialization_lib.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mclass_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"function\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0mfn_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         return _retrieve_class_or_fn(\n\u001b[0m\u001b[1;32m    679\u001b[0m             \u001b[0mfn_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0mregistered_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/serialization_lib.py\u001b[0m in \u001b[0;36m_retrieve_class_or_fn\u001b[0;34m(name, registered_name, module, obj_type, full_config, custom_objects)\u001b[0m\n\u001b[1;32m    810\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m     raise TypeError(\n\u001b[0m\u001b[1;32m    813\u001b[0m         \u001b[0;34mf\"Could not locate {obj_type} '{name}'. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m         \u001b[0;34m\"Make sure custom classes are decorated with \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Could not locate function 'mse'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'keras.metrics', 'class_name': 'function', 'config': 'mse', 'registered_name': 'mse'}"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "만약 학습할 데이터가 부족한 경우 (샘플이 부족한 경우)"
      ],
      "metadata": {
        "id": "cDK4qyKyCr1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# 1. 데이터 불러오기 및 전처리\n",
        "data = pd.read_excel(file_path).dropna()\n",
        "  # null값이 있는 행을 제거\n",
        "\n",
        "\n",
        "#2. 입력 변수(X)와 출력 변수(y) 설정\n",
        "X = data[['외경/폭', '두께', '등록 길이']]#,'등록 중량']]\n",
        "y = data[['step1 최종 작업 시간', 'step2 최종 작업 시간',\n",
        "         'step3 최종 작업 시간', 'step4 최종 작업 시간',\n",
        "         'step5 최종 작업 시간', 'step6 최종 작업 시간']]\n",
        "\n",
        "# 데이터 분할\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 특성 스케일링\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# 2. 신경망 모델 구축\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(6)  # 출력 노드 수는 예측하고자 하는 작업 시간의 수\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# 3. 모델 학습\n",
        "# Determine the number of training samples\n",
        "num_train_samples = X_train.shape[0]\n",
        "\n",
        "# Define minimum samples required for validation_split=0.1\n",
        "min_samples_for_validation = 10  # Adjust this threshold as needed\n",
        "\n",
        "if num_train_samples >= min_samples_for_validation:\n",
        "    validation_split = 0.1\n",
        "    print(f\"Using validation_split={validation_split} with {num_train_samples} training samples.\")\n",
        "else:\n",
        "    validation_split = 0\n",
        "    print(f\"Insufficient training samples ({num_train_samples}). Skipping validation split.\")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_split=validation_split,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 4. 모델 평가\n",
        "loss, mae = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('\\n신경망 모델 평가:')\n",
        "print('테스트 세트의 MSE:', loss)\n",
        "print('테스트 세트의 MAE:', mae)\n",
        "\n",
        "# 각 스텝별 평가 지표 계산\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "for i, step in enumerate(['step1', 'step2', 'step3', 'step4', 'step5', 'step6']):\n",
        "    print(f\"\\n{step} 작업 시간(분) 평가:\")\n",
        "    mse = mean_squared_error(y_test.iloc[:, i], y_pred[:, i])\n",
        "    mae = mean_absolute_error(y_test.iloc[:, i], y_pred[:, i])\n",
        "    r2 = r2_score(y_test.iloc[:, i], y_pred[:, i])\n",
        "    print('MSE:', mse)\n",
        "    print('MAE:', mae)\n",
        "    print('R² 점수:', r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsxHx1jkCuPy",
        "outputId": "890a9ab4-9612-404d-ef1c-76be5b30503f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using validation_split=0.1 with 68 training samples.\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 165ms/step - loss: 518.4780 - mae: 12.0048 - val_loss: 140.3217 - val_mae: 11.2355\n",
            "Epoch 2/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 517.0744 - mae: 11.9450 - val_loss: 139.6931 - val_mae: 11.2093\n",
            "Epoch 3/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 873.1252 - mae: 12.6513 - val_loss: 139.0870 - val_mae: 11.1841\n",
            "Epoch 4/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 513.8115 - mae: 11.8301 - val_loss: 138.4981 - val_mae: 11.1597\n",
            "Epoch 5/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 874.1264 - mae: 12.7002 - val_loss: 137.9179 - val_mae: 11.1358\n",
            "Epoch 6/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 870.7508 - mae: 12.5798 - val_loss: 137.3269 - val_mae: 11.1111\n",
            "Epoch 7/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 513.3864 - mae: 11.8328 - val_loss: 136.7200 - val_mae: 11.0853\n",
            "Epoch 8/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 870.9086 - mae: 12.6008 - val_loss: 136.0989 - val_mae: 11.0592\n",
            "Epoch 9/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 868.2371 - mae: 12.5110 - val_loss: 135.4349 - val_mae: 11.0311\n",
            "Epoch 10/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 511.7744 - mae: 11.7626 - val_loss: 134.7602 - val_mae: 11.0022\n",
            "Epoch 11/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 513.2709 - mae: 11.8230 - val_loss: 134.0485 - val_mae: 10.9719\n",
            "Epoch 12/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 867.1661 - mae: 12.4564 - val_loss: 133.2956 - val_mae: 10.9397\n",
            "Epoch 13/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 509.7076 - mae: 11.6832 - val_loss: 132.5201 - val_mae: 10.9063\n",
            "Epoch 14/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 866.3205 - mae: 12.4257 - val_loss: 131.6884 - val_mae: 10.8704\n",
            "Epoch 15/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 505.4010 - mae: 11.5166 - val_loss: 130.8176 - val_mae: 10.8323\n",
            "Epoch 16/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 505.6160 - mae: 11.5496 - val_loss: 129.8879 - val_mae: 10.7915\n",
            "Epoch 17/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 861.6160 - mae: 12.2825 - val_loss: 128.8941 - val_mae: 10.7476\n",
            "Epoch 18/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 503.7780 - mae: 11.4424 - val_loss: 127.8398 - val_mae: 10.7004\n",
            "Epoch 19/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 857.0437 - mae: 12.1454 - val_loss: 126.7221 - val_mae: 10.6503\n",
            "Epoch 20/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 855.6442 - mae: 12.0841 - val_loss: 125.5376 - val_mae: 10.5967\n",
            "Epoch 21/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 853.6180 - mae: 12.0178 - val_loss: 124.2804 - val_mae: 10.5391\n",
            "Epoch 22/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 498.0939 - mae: 11.2591 - val_loss: 122.9567 - val_mae: 10.4778\n",
            "Epoch 23/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 499.0674 - mae: 11.3139 - val_loss: 121.5567 - val_mae: 10.4123\n",
            "Epoch 24/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 492.6011 - mae: 11.0494 - val_loss: 120.0803 - val_mae: 10.3426\n",
            "Epoch 25/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 849.0773 - mae: 11.8701 - val_loss: 118.4918 - val_mae: 10.2668\n",
            "Epoch 26/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 842.6846 - mae: 11.6336 - val_loss: 116.7728 - val_mae: 10.1839\n",
            "Epoch 27/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 487.8011 - mae: 10.8385 - val_loss: 114.9445 - val_mae: 10.0947\n",
            "Epoch 28/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 485.1158 - mae: 10.7420 - val_loss: 113.0064 - val_mae: 9.9988\n",
            "Epoch 29/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 481.6688 - mae: 10.5519 - val_loss: 110.9732 - val_mae: 9.8972\n",
            "Epoch 30/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 829.4701 - mae: 11.1095 - val_loss: 108.8280 - val_mae: 9.7891\n",
            "Epoch 31/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 479.1666 - mae: 10.4954 - val_loss: 106.5826 - val_mae: 9.6740\n",
            "Epoch 32/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 475.0373 - mae: 10.3070 - val_loss: 104.1971 - val_mae: 9.5505\n",
            "Epoch 33/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 472.8426 - mae: 10.2078 - val_loss: 101.6835 - val_mae: 9.4184\n",
            "Epoch 34/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 821.0027 - mae: 10.8194 - val_loss: 99.0326 - val_mae: 9.2768\n",
            "Epoch 35/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 817.8031 - mae: 10.7043 - val_loss: 96.2780 - val_mae: 9.1267\n",
            "Epoch 36/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 810.2141 - mae: 10.3644 - val_loss: 93.4133 - val_mae: 8.9674\n",
            "Epoch 37/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 457.0605 - mae: 9.4733 - val_loss: 90.4740 - val_mae: 8.8002\n",
            "Epoch 38/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 803.5099 - mae: 10.0955 - val_loss: 87.4066 - val_mae: 8.6226\n",
            "Epoch 39/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 798.1741 - mae: 9.8634 - val_loss: 84.2528 - val_mae: 8.4356\n",
            "Epoch 40/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 446.4037 - mae: 8.9647 - val_loss: 81.0443 - val_mae: 8.2462\n",
            "Epoch 41/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 443.6159 - mae: 8.8049 - val_loss: 77.7598 - val_mae: 8.0473\n",
            "Epoch 42/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 786.0334 - mae: 9.3279 - val_loss: 74.3846 - val_mae: 7.8374\n",
            "Epoch 43/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 781.9453 - mae: 9.1253 - val_loss: 70.9669 - val_mae: 7.6183\n",
            "Epoch 44/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 776.7879 - mae: 8.8974 - val_loss: 67.5266 - val_mae: 7.3901\n",
            "Epoch 45/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 428.3893 - mae: 8.0079 - val_loss: 64.0900 - val_mae: 7.1537\n",
            "Epoch 46/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 425.0127 - mae: 7.8337 - val_loss: 60.6495 - val_mae: 6.9080\n",
            "Epoch 47/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 761.8007 - mae: 8.1884 - val_loss: 57.1946 - val_mae: 6.6515\n",
            "Epoch 48/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 758.8406 - mae: 8.0420 - val_loss: 53.7896 - val_mae: 6.3870\n",
            "Epoch 49/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 411.1479 - mae: 7.0285 - val_loss: 50.4789 - val_mae: 6.1261\n",
            "Epoch 50/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 407.2995 - mae: 6.7979 - val_loss: 47.2535 - val_mae: 5.8694\n",
            "Epoch 51/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 403.6388 - mae: 6.5509 - val_loss: 44.1232 - val_mae: 5.6208\n",
            "Epoch 52/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 398.9156 - mae: 6.2811 - val_loss: 41.1169 - val_mae: 5.3679\n",
            "Epoch 53/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 733.5250 - mae: 6.7568 - val_loss: 38.2197 - val_mae: 5.1088\n",
            "Epoch 54/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 391.1868 - mae: 5.7966 - val_loss: 35.5316 - val_mae: 4.8551\n",
            "Epoch 55/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 720.7897 - mae: 6.0864 - val_loss: 33.0042 - val_mae: 4.6313\n",
            "Epoch 56/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 381.7448 - mae: 5.1693 - val_loss: 30.6879 - val_mae: 4.4218\n",
            "Epoch 57/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 379.5021 - mae: 5.0502 - val_loss: 28.5735 - val_mae: 4.2292\n",
            "Epoch 58/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 710.3448 - mae: 5.6887 - val_loss: 26.6341 - val_mae: 4.0463\n",
            "Epoch 59/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 708.2341 - mae: 5.6970 - val_loss: 24.9256 - val_mae: 3.8749\n",
            "Epoch 60/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 702.9915 - mae: 5.4755 - val_loss: 23.4459 - val_mae: 3.7488\n",
            "Epoch 61/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 696.9554 - mae: 5.1683 - val_loss: 22.1928 - val_mae: 3.6496\n",
            "Epoch 62/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 367.2613 - mae: 4.4924 - val_loss: 21.1415 - val_mae: 3.5685\n",
            "Epoch 63/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 362.0461 - mae: 4.1492 - val_loss: 20.2935 - val_mae: 3.5014\n",
            "Epoch 64/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 361.5673 - mae: 4.2141 - val_loss: 19.6234 - val_mae: 3.4452\n",
            "Epoch 65/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 685.0319 - mae: 4.9309 - val_loss: 19.1482 - val_mae: 3.4317\n",
            "Epoch 66/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 356.3483 - mae: 3.9930 - val_loss: 18.8218 - val_mae: 3.4208\n",
            "Epoch 67/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 356.1875 - mae: 4.0745 - val_loss: 18.6473 - val_mae: 3.4246\n",
            "Epoch 68/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 353.2342 - mae: 3.9289 - val_loss: 18.6177 - val_mae: 3.4337\n",
            "Epoch 69/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 352.5781 - mae: 3.9935 - val_loss: 18.7205 - val_mae: 3.4451\n",
            "Epoch 70/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 350.1507 - mae: 3.9224 - val_loss: 18.9550 - val_mae: 3.4590\n",
            "Epoch 71/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 666.1249 - mae: 4.6634 - val_loss: 19.3444 - val_mae: 3.4774\n",
            "Epoch 72/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 662.5003 - mae: 4.6298 - val_loss: 19.8320 - val_mae: 3.4966\n",
            "Epoch 73/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 344.7651 - mae: 3.7629 - val_loss: 20.3418 - val_mae: 3.5151\n",
            "Epoch 74/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 343.8360 - mae: 3.8253 - val_loss: 20.9411 - val_mae: 3.5362\n",
            "Epoch 75/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 654.1253 - mae: 4.5908 - val_loss: 21.7131 - val_mae: 3.5627\n",
            "Epoch 76/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 650.6640 - mae: 4.5002 - val_loss: 22.5441 - val_mae: 3.5882\n",
            "Epoch 77/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 646.7970 - mae: 4.4190 - val_loss: 23.4306 - val_mae: 3.6132\n",
            "Epoch 78/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 643.8947 - mae: 4.4009 - val_loss: 24.3787 - val_mae: 3.6381\n",
            "Epoch 79/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 642.1872 - mae: 4.4732 - val_loss: 25.3999 - val_mae: 3.6650\n",
            "Epoch 80/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 638.7635 - mae: 4.4495 - val_loss: 26.4855 - val_mae: 3.7003\n",
            "Epoch 81/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 333.1244 - mae: 3.6797 - val_loss: 27.5003 - val_mae: 3.7336\n",
            "Epoch 82/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 633.9532 - mae: 4.4586 - val_loss: 28.7466 - val_mae: 3.7730\n",
            "Epoch 83/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 631.2507 - mae: 4.4767 - val_loss: 30.0651 - val_mae: 3.8106\n",
            "Epoch 84/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 330.0101 - mae: 3.7659 - val_loss: 31.2418 - val_mae: 3.8428\n",
            "Epoch 85/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 327.8789 - mae: 3.6752 - val_loss: 32.5424 - val_mae: 3.8768\n",
            "Epoch 86/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 327.1281 - mae: 3.7181 - val_loss: 33.9345 - val_mae: 3.9113\n",
            "Epoch 87/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 326.0014 - mae: 3.7596 - val_loss: 35.4136 - val_mae: 3.9466\n",
            "Epoch 88/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 324.8007 - mae: 3.7151 - val_loss: 36.9645 - val_mae: 3.9820\n",
            "Epoch 89/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 322.7141 - mae: 3.7114 - val_loss: 38.6111 - val_mae: 4.0175\n",
            "Epoch 90/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 613.1954 - mae: 4.4554 - val_loss: 40.5352 - val_mae: 4.0573\n",
            "Epoch 91/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 319.9703 - mae: 3.6957 - val_loss: 42.2483 - val_mae: 4.0896\n",
            "Epoch 92/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 318.7458 - mae: 3.7337 - val_loss: 44.0556 - val_mae: 4.1221\n",
            "Epoch 93/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 318.3247 - mae: 3.7679 - val_loss: 45.9212 - val_mae: 4.1554\n",
            "Epoch 94/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 604.5334 - mae: 4.5885 - val_loss: 48.0763 - val_mae: 4.1923\n",
            "Epoch 95/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 316.8956 - mae: 3.8219 - val_loss: 49.9746 - val_mae: 4.2262\n",
            "Epoch 96/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 316.0016 - mae: 3.8603 - val_loss: 51.9385 - val_mae: 4.2683\n",
            "Epoch 97/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 597.8987 - mae: 4.7094 - val_loss: 54.2573 - val_mae: 4.3173\n",
            "Epoch 98/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 594.0145 - mae: 4.6343 - val_loss: 56.5762 - val_mae: 4.3741\n",
            "Epoch 99/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 594.6933 - mae: 4.8868 - val_loss: 58.8112 - val_mae: 4.4265\n",
            "Epoch 100/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 589.5298 - mae: 4.7272 - val_loss: 61.0695 - val_mae: 4.4778\n",
            "\n",
            "신경망 모델 평가:\n",
            "테스트 세트의 MSE: 17.40324592590332\n",
            "테스트 세트의 MAE: 2.7800345420837402\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7b6a81bc56c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "\n",
            "step1 작업 시간(분) 평가:\n",
            "MSE: 6.127354538631849\n",
            "MAE: 1.864412143495348\n",
            "R² 점수: -0.5656523769660482\n",
            "\n",
            "step2 작업 시간(분) 평가:\n",
            "MSE: 4.728895843296792\n",
            "MAE: 1.695178487565782\n",
            "R² 점수: -1.215740290138918\n",
            "\n",
            "step3 작업 시간(분) 평가:\n",
            "MSE: 4.980975971927245\n",
            "MAE: 1.8530816713968916\n",
            "R² 점수: -0.3933882585234352\n",
            "\n",
            "step4 작업 시간(분) 평가:\n",
            "MSE: 5.767399991505477\n",
            "MAE: 1.8058488368988037\n",
            "R² 점수: -0.24000477600452208\n",
            "\n",
            "step5 작업 시간(분) 평가:\n",
            "MSE: 27.947131530702062\n",
            "MAE: 4.135679642359416\n",
            "R² 점수: 0.1045137290789\n",
            "\n",
            "step6 작업 시간(분) 평가:\n",
            "MSE: 54.86771994075427\n",
            "MAE: 5.326006656222874\n",
            "R² 점수: -2.8377318036363683\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AEzMM_mUCutJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}